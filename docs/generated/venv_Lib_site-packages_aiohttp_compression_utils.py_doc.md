# `aiohttp.compression_utils` – Developer Documentation  

---

## 1. Module Purpose  

### What the file is responsible for  
`compression_utils.py` provides a thin, asyncio‑friendly abstraction over several compression/decompression algorithms that aiohttp can use for HTTP payload encoding (e.g., `gzip`, `deflate`, `br` and `zstd`). It:

1. Detects optional third‑party libraries (`brotli`, `zstandard`) and records their availability.  
2. Wraps the standard library `zlib` module in a **backend wrapper** that can be swapped at runtime (useful for testing or custom implementations).  
3. Exposes high‑level, non‑blocking compressor and decompressor classes (`ZLibCompressor`, `ZLibDecompressor`, `BrotliDecompressor`, `ZSTDDecompressor`).  
4. Provides helpers for determining the correct `zlib` window‑bits value based on the desired HTTP content‑encoding (`gzip` vs. raw `deflate`).  

### Why it exists in the project  
aiohttp supports transparent request/response body compression. Because compression can be CPU‑intensive, the library must:

* **Avoid blocking the event loop** – large payloads are off‑loaded to a thread pool executor.  
* **Support multiple algorithms** – HTTP/1.1 may negotiate `gzip`, `deflate`, `br`, or `zstd`.  
* **Allow backend replacement** – tests or alternative C extensions can be injected without touching the rest of the codebase.  

The module centralises all of this logic, keeping the rest of aiohttp clean and focused on protocol handling.

---

## 2. Key Components  

### Constants  

| Name | Meaning |
|------|---------|
| `MAX_SYNC_CHUNK_SIZE` | Threshold (1024 bytes) that decides whether a compression/decompression operation runs synchronously in the event loop (`≤`) or is delegated to an executor (`>`). |
| `HAS_BROTLI` | `True` if either `brotlicffi` or `brotli` could be imported. |
| `HAS_ZSTD` | `True` if the (backport) `zstandard` library could be imported. |

---

### Protocol Definitions (type‑checking only)  

| Protocol | Purpose |
|----------|---------|
| `ZLibCompressObjProtocol` | Minimal interface for a zlib compression object (`compress`, `flush`). |
| `ZLibDecompressObjProtocol` | Minimal interface for a zlib decompression object (`decompress`, `flush`, `eof` property). |
| `ZLibBackendProtocol` | Describes the full API that a zlib‑like backend must provide (constants, `compressobj`, `decompressobj`, convenience `compress`/`decompress`). |

These are used only for static typing; they do **not** affect runtime behaviour.

---

### `ZLibBackendWrapper`  

* **What it does** – Wraps any object that conforms to `ZLibBackendProtocol`.  
* **Inputs** – `_zlib_backend`: an object exposing the zlib API (normally the standard `zlib` module).  
* **Outputs** – Provides the same attributes and methods as the wrapped backend, plus a printable `name` property.  
* **Internal logic** – All attribute accesses are forwarded; unknown attributes fall back to `__getattr__`.  
* **Public API** – The wrapper itself is not meant to be instantiated by library users; it is used internally to expose a mutable backend via `ZLibBackend`.  

---

### Global Backend Instance  

```python
ZLibBackend: ZLibBackendWrapper = ZLibBackendWrapper(zlib)
```

* Holds the *current* zlib backend.  
* Can be replaced at runtime via `set_zlib_backend`.

---

### `set_zlib_backend(new_zlib_backend: ZLibBackendProtocol) -> None`  

* Replaces the underlying backend used by `ZLibBackend`.  
* Handy for tests that want to inject a mock implementation.

---

### `encoding_to_mode(encoding: Optional[str] = None, suppress_deflate_header: bool = False) -> int`  

* **Purpose** – Compute the `wbits` argument for zlib based on the desired HTTP content‑encoding.  
* **Parameters**  
  * `encoding` – `"gzip"` for gzip format, otherwise raw deflate.  
  * `suppress_deflate_header` – When `True` and `encoding` is not gzip, returns a negative value to ask zlib to omit the zlib header (raw deflate).  
* **Return** – Integer suitable for the `wbits` parameter of `zlib.compressobj` / `zlib.decompressobj`.  

---

### `ZlibBaseHandler` (abstract)  

* Stores common configuration for compressors and decompressors:  

| Attribute | Meaning |
|-----------|---------|
| `_mode` | The integer wbits value passed to zlib. |
| `_executor` | Optional `concurrent.futures.Executor` for off‑loading heavy work. |
| `_max_sync_chunk_size` | Threshold that triggers executor usage. |

* No public methods; only subclasses expose APIs.

---

### `ZLibCompressor`  

* **What it does** – Provides async‑compatible gzip/deflate compression.  
* **Constructor parameters**  

| Parameter | Type | Description |
|-----------|------|-------------|
| `encoding` | `Optional[str]` | `"gzip"` or `None` (raw deflate). |
| `suppress_deflate_header` | `bool` | When `True` and `encoding` is not `"gzip"`, raw deflate is emitted (no zlib header). |
| `level` | `Optional[int]` | Compression level (0‑9) forwarded to zlib. |
| `wbits` | `Optional[int]` | Directly overrides the calculated wbits value. |
| `strategy` | `Optional[int]` | zlib compression strategy flag. |
| `executor` | `Optional[Executor]` | Executor used for large payloads. |
| `max_sync_chunk_size` | `Optional[int]` | Override the default 1024 byte threshold. |

* **Public methods**  

| Method | Signature | Behaviour |
|--------|-----------|-----------|
| `compress_sync` | `(data: bytes) -> bytes` | Direct, blocking call to the underlying zlib `compress` method. |
| `compress` | `async (data: bytes) -> bytes` | If `len(data) > _max_sync_chunk_size`, runs `compressor.compress` in the configured executor; otherwise calls `compress_sync`. |
| `flush` | `(mode: Optional[int] = None) -> bytes` | Synchronously flushes the compressor. Defaults to `Z_FINISH` (final block). |

* **Important notes** – The `compress` method is **not cancellation‑safe** when paired with `flush`. If a task is cancelled after a compression call, internal compressor state may become invalid, and the connection must be closed. For cancellation‑safe use (e.g., WebSocket frames) callers should protect the whole *compress‑flush‑send* sequence with `asyncio.shield` and a lock.

---

### `ZLibDecompressor`  

* **What it does** – Async‑compatible gzip/deflate decompression.  
* **Constructor parameters** – Same as `ZLibCompressor` (minus level/strategy).  

* **Public methods**  

| Method | Signature | Behaviour |
|--------|-----------|-----------|
| `decompress_sync` | `(data: bytes, max_length: int = 0) -> bytes` | Direct call to `decompressobj.decompress`. |
| `decompress` | `async (data: bytes, max_length: int = 0) -> bytes` | Off‑loads to executor when payload exceeds `_max_sync_chunk_size`. |
| `flush` | `(length: int = 0) -> bytes` | Calls the underlying zlib `flush`. If `length` is zero, the default flush is used. |
| `eof` (property) | `bool` | Exposes `decompressobj.eof` – indicates end‑of‑stream has been reached. |

* **Notes** – Mirrors the same cancellation caveats as the compressor: flushing after a cancelled `decompress` may corrupt internal state.

---

### `BrotliDecompressor`  

* **Purpose** – Provide a uniform API for Brotli decompression, regardless of whether the runtime uses the `brotlicffi` or the `Brotli` package.  
* **Constructor** – Raises `RuntimeError` if neither package is available (`HAS_BROTLI` is `False`).  
* **Public methods**  

| Method | Signature | Behaviour |
|--------|-----------|-----------|
| `decompress_sync` | `(data: bytes) -> bytes` | Calls the underlying object's `decompress` (or `process` for older API). |
| `flush` | `() -> bytes` | Calls `flush` if present; otherwise returns empty `bytes`. |

* No asynchronous wrapper – Brotli decompression is typically fast enough to run synchronously.

---

### `ZSTDDecompressor`  

* **Purpose** – Uniform API for Zstandard decompression using the backport library (`backports.zstd`).  
* **Constructor** – Raises `RuntimeError` when `HAS_ZSTD` is `False`.  
* **Public methods**  

| Method | Signature | Behaviour |
|--------|-----------|-----------|
| `decompress_sync` | `(data: bytes) -> bytes` | Calls `ZstdDecompressor.decompress`. |
| `flush` | `() -> bytes` | Returns empty `bytes` (ZSTD decompressor does not need an explicit flush). |

* Also synchronous only – ZSTD decompression is usually non‑blocking for typical payload sizes.

---

## 3. Dependencies & Relationships  

### Imports  

| Module | Reason |
|--------|--------|
| `asyncio` | Off‑loading work to the event loop’s executor (`run_in_executor`). |
| `sys` | Detect Python version to import the right *Buffer* typing and conditional ZSTD import. |
| `zlib` | Core compression/decompression implementation for gzip/deflate. |
| `concurrent.futures.Executor` | Type hint for an optional executor supplied by callers. |
| `typing` (`Any`, `Final`, `Optional`, `Protocol`, `TypedDict`, `cast`) | Type‑checking utilities and runtime casts. |
| Conditional import of `brotlicffi` / `brotli` | Brotli support (optional). |
| Conditional import of `compression.zstd` (Python 3.14+) or `backports.zstd` | Zstandard support (optional). |

### Interaction with the rest of aiohttp  

* **Consumers** – The HTTP server/client implementation in aiohttp imports these classes when building response/request bodies (`aiohttp.web_response`, `aiohttp.streams`). The server may instantiate a `ZLibCompressor` when the client requests `Accept‑Encoding: gzip`.  
* **Providers** – This module depends only on external libraries (`zlib`, optional Brotli/ZSTD) and does **not** import any other aiohttp internal modules, keeping it a low‑coupling utility.  
* **Extensibility** – Because the backend wrapper can be swapped via `set_zlib_backend`, unit tests or alternative implementations (e.g., a pure‑Python zlib clone) can be used without touching request/response handling code.  

---

## 4. Workflow Description  

### Compression (gzip/deflate)  

1. **Instantiation** – `ZLibCompressor` is created with desired parameters (`encoding`, `level`, etc.).  
2. **Backend selection** – It captures the current `ZLibBackend` (a wrapper around the global `zlib` module).  
3. **Compressor object** – Calls `compressobj(wbits=mode, ...)` on the backend, yielding a low‑level zlib compressor.  
4. **Compress call** (`await compressor.compress(data)`)  
   * Checks payload size against `_max_sync_chunk_size`.  
   * If **large**, schedules `compressor.compress(data)` on the provided executor (`run_in_executor`).  
   * If **small**, invokes `compress_sync`, which directly delegates to the low‑level object's `compress`.  
5. **Flush** – After the final chunk, caller invokes `compressor.flush()` (synchronously) to emit any remaining bytes (default `Z_FINISH`).  

### Decompression (gzip/deflate)  

1. **Instantiation** – `ZLibDecompressor` is constructed with the same mode logic.  
2. **Backend selection** – Same wrapper approach.  
3. **Decompressor object** – Calls `decompressobj(wbits=mode)`.  
4. **Decompress call** (`await decompressor.decompress(data)`)  
   * Mirrors the size check and executor off‑load logic of the compressor.  
5. **Flush / EOF** – `flush()` returns any buffered output; `eof` tells whether the stream has been fully consumed.  

### Brotli & ZSTD  

* No async handling – the classes expose a synchronous `decompress_sync` method.  
* Construction fails early if the required third‑party library is missing, providing a clear error message.

---

## 5. Usage Examples  

### (a) Gzip compression in an aiohttp handler  

```python
import asyncio
from aiohttp import web
from aiohttp.compression_utils import ZLibCompressor

async def handler(request):
    compressor = ZLibCompressor(encoding="gzip", level=5)

    # Simulate a large payload
    data = b"your response body" * 5000

    # Compress (may be off‑loaded to a thread pool)
    compressed = await compressor.compress(data)

    # Finish the stream
    compressed += compressor.flush()

    return web.Response(body=compressed,
                        headers={"Content-Encoding": "gzip"})
```

### (b) Deflate decompression of a request body  

```python
from aiohttp.compression_utils import ZLibDecompressor

async def receive(request):
    raw = await request.read()          # contains raw deflate bytes
    decompressor = ZLibDecompressor()
    data = await decompressor.decompress(raw)
    # `data` now holds the original uncompressed payload
    ...
```

### (c) Brotli decompression (synchronous)  

```python
from aiohttp.compression_utils import BrotliDecompressor

def decode_brotli(payload: bytes) -> bytes:
    brotli_decoder = BrotliDecompressor()
    return brotli_decoder.decompress_sync(payload)
```

### (d) Swapping the zlib backend for testing  

```python
from aiohttp.compression_utils import set_zlib_backend, ZLibBackendWrapper

class DummyZlib:
    # implement the minimal ZLibBackendProtocol members used by the code
    ...

set_zlib_backend(DummyZlib())
# Subsequent ZLibCompressor/ZLibDecompressor instances will use DummyZlib
```

---

## 6. Notes for Developers  

| Area | Guidance / Gotchas |
|------|--------------------|
| **Cancellation safety** | `ZLibCompressor.compress` and `ZLibDecompressor.decompress` are **not** cancellation‑safe when followed by a `flush`. If a task is cancelled after a compression/decompression call, the internal zlib object may be left in an inconsistent state. The caller must either (a) let the connection close, or (b) protect the whole “compress‑flush‑send”/“decompress‑flush” sequence with `asyncio.shield` and a lock. |
| **Executor selection** | The optional `executor` argument is passed straight to `run_in_executor`. If `None`, the default executor of the current event loop is used. Providing a custom `ThreadPoolExecutor` can improve performance when many concurrent compressions occur. |
| **Chunk size threshold** | `MAX_SYNC_CHUNK_SIZE` is deliberately low (1 KB) to avoid blocking the event loop on typical HTTP payloads. Adjust via `max_sync_chunk_size` if the application knows its workload and wants to reduce thread‑pool usage. |
| **Header handling** | `encoding_to_mode` uses `+16` for gzip to request a gzip wrapper (zlib’s “gzip” format). For raw deflate, passing a negative wbits suppresses the zlib header. This mirrors the expectations of the HTTP `Content-Encoding` header. |
| **Optional algorithm availability** | Import failures are turned into `HAS_BROTLI` / `HAS_ZSTD` booleans. Instantiating the corresponding decompressor when the library is missing raises a clear `RuntimeError`. This design avoids import‑time crashes and allows aiohttp to gracefully skip unsupported encodings. |
| **Backend mutability** | `set_zlib_backend` mutates the global `ZLibBackend`. All subsequently created compressor/decompressor objects capture the *current* backend at construction time. Existing objects continue to use the backend they were created with. |
| **Type safety** | The module heavily uses `Protocol` and `TypedDict` for static analysis (mypy, pyright). At runtime they are no‑ops, so they add no overhead. |
| **Python version quirks** | The Buffer union type handling differs between Python 3.12+ and earlier versions to keep type‑checking accurate across supported interpreters. |
| **ZSTD import path** | Starting with Python 3.14 the upstream `compression.zstd` module is preferred; older versions fall back to the backport. The comment `# TODO(PY314): Remove mentions of backports.zstd…` indicates a planned future cleanup. |

--- 

**End of documentation**.